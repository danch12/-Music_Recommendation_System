{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:43.029308Z",
     "start_time": "2020-04-08T14:25:42.997421Z"
    }
   },
   "outputs": [],
   "source": [
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import config\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D,AveragePooling2D, BatchNormalization,Dropout,Flatten,Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.util as util\n",
    "\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, pairwise_distances\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import io\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import glob\n",
    "\n",
    "\n",
    "import pydub\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from shutil import copyfileobj\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen, Request\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T19:41:28.601549Z",
     "start_time": "2020-02-21T19:41:28.114169Z"
    }
   },
   "outputs": [],
   "source": [
    "music_df =pd.read_csv('music_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:21:19.978448Z",
     "start_time": "2020-02-16T17:21:19.965530Z"
    }
   },
   "source": [
    "These functions are to enable us to find similar songs even if they do not appear in the mixesdb dataset. This will happen quite a lot as there are many songs out there.\n",
    "\n",
    "\n",
    "im in two minds about whether I should scale the data or not. Im sort of thinking if the neural net gave bigger numbers to certain features it may mean that they should have bigger influence anyway. I will try both ways to see which one produces better results, although very subjective what best results would look like.\n",
    "\n",
    "\n",
    "Also I was wondering if I should use Cosine similarity vs Euclidean distance so did a bit of reading and found this article -https://cmry.github.io/notes/euclidean-v-cosine . Bascially says that if we care about magnitude we should use Euclidean, and I think we do care about magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:31.451928Z",
     "start_time": "2020-04-08T14:25:31.081048Z"
    }
   },
   "outputs": [],
   "source": [
    "client_id= config.client_id\n",
    "client_secret =config.client_secret\n",
    "\n",
    "username = '1143043561'\n",
    "auth = SpotifyClientCredentials(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    token = auth.get_access_token()\n",
    "except:\n",
    "    os.remove(f'.cache-{username}')\n",
    "    token = auth.get_access_token()\n",
    "    \n",
    "#create spotify object\n",
    "spotify = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:31.461997Z",
     "start_time": "2020-04-08T14:25:31.453834Z"
    }
   },
   "outputs": [],
   "source": [
    "def closest_k_nodes(node, nodes,k=5):\n",
    "    node=node.reshape(1,-1)\n",
    "    dist_2 = pairwise_distances(nodes,node)\n",
    "    smallest_inds=np.argsort(dist_2[:,0])[:k]\n",
    "    smallest_dists=dist_2[smallest_inds]\n",
    "    return (smallest_inds, smallest_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:32.187345Z",
     "start_time": "2020-04-08T14:25:31.603551Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'music_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ac31dc77e0ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msong_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmusic_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_songs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiff_genre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'no'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msame_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'yes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msimilar_tempo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'yes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscaled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msong_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msong_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0msong_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'music_df' is not defined"
     ]
    }
   ],
   "source": [
    "def find_similar(song_id,song_list=music_df,num_songs=5,diff_genre='no',same_key='yes',similar_tempo='yes',margin=3,scaled=False):\n",
    "    \n",
    "    \n",
    "    song_index=song_list[song_list.id==song_id].index[0]\n",
    "    \n",
    "   \n",
    "    orig_key = song_list.loc[song_index,'key']\n",
    "    orig_tempo= song_list.loc[song_index, 'tempo']\n",
    "    orig_genre= song_list.loc[song_index,'genre_approx']\n",
    "    node = song_list.loc[song_index]\n",
    "    \n",
    "    #check if you want songs of same key\n",
    "    if same_key=='yes':\n",
    "    #if yes then filter out other keys    \n",
    "        print(f'key:{orig_key}')\n",
    "        song_list = song_list[song_list.key ==orig_key]\n",
    "    #can also enter number to specify what key you want    \n",
    "    elif type(same_key) !=str:\n",
    "        song_list = song_list[song_list.key==same_key]\n",
    "\n",
    "\n",
    "    # check if you want similar tempo    \n",
    "    if similar_tempo=='yes':\n",
    "        print(f'tempo:{orig_tempo}')\n",
    "        #if yes can also specify how similar you want it \n",
    "        song_list=song_list[song_list.tempo.between(int(orig_tempo)-margin,int(orig_tempo)+margin)]\n",
    "        \n",
    "    elif type(similar_tempo) !=str:\n",
    "        #can also specify a specific tempo that you want\n",
    "        song_list = song_list[song_list.tempo.between(int(similar_tempo)-margin,int(similar_tempo)+margin)]\n",
    "    \n",
    "    #check if you want a different genre\n",
    "    if diff_genre=='yes':\n",
    "        print(f'genre:{orig_genre}')\n",
    "        song_list= song_list[song_list.genre_approx != orig_genre]\n",
    "        \n",
    "    \n",
    "    #adds requested song back into dataframe in case it was filtered out\n",
    "    song_list=song_list.append(node,ignore_index=True)\n",
    "    song_id_info=song_list.copy()\n",
    "    #makes sure certain columns are ints as they come as strings from spotify\n",
    "    song_list.key=song_list.key.astype(int)\n",
    "    song_list['mode']=song_list['mode'].astype(int)\n",
    "    song_list.time_signature=song_list.time_signature.astype(int)\n",
    "    #exclude any other column which is a string\n",
    "    song_list=song_list.select_dtypes(exclude=object)\n",
    "    \n",
    "    #scale the data\n",
    "    if scaled==True:\n",
    "        scaler = StandardScaler()\n",
    "        song_list = scaler.fit_transform(song_list)\n",
    "\n",
    "        node = song_list[-1]\n",
    "        nodes = song_list\n",
    "    \n",
    "    else:\n",
    "        node=np.asarray(song_list.iloc[-1])\n",
    "        nodes=song_list\n",
    "    \n",
    "    #find closest song using euclidean distance\n",
    "    closest_inds,distances = closest_k_nodes(node,nodes,num_songs)\n",
    "    \n",
    "    #get song ids of closest songs\n",
    "    song_ids=song_id_info.loc[closest_inds,'id']\n",
    "    #make sure there is no NANs \n",
    "    song_ids=[x for x in song_ids if str(x) != 'nan']\n",
    "    \n",
    "    #find track names using spotify API\n",
    "    tracks=spotify.tracks(list(song_ids))\n",
    "    song_names=[]\n",
    "    for track in tracks['tracks']:\n",
    "        song_names.append((track['name'],track['artists'][0]['name']))\n",
    "\n",
    "    #create dataframe of songs and their euclidean distance from the original song\n",
    "    close_song_df=pd.DataFrame({'song_ids':song_ids,\n",
    "                                'song_names':song_names,\n",
    "                                'distances':distances.flatten()})\n",
    "    return (close_song_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:32.191058Z",
     "start_time": "2020-04-08T14:25:31.809Z"
    }
   },
   "outputs": [],
   "source": [
    "def spectrogram_then_latent(url, song_id, name, model):\n",
    "    '''basically the same as the function i used to\n",
    "    create a load of spectrograms but just for 1 this time\n",
    "    takes  url and turns the preview mp3 \n",
    "        into a spectrogram and then uses a model to \n",
    "        extract latent features'''   \n",
    "\n",
    "    if url != None:\n",
    "        try:\n",
    "            mp3_url = url\n",
    "            wav = io.BytesIO()\n",
    "            with urlopen(mp3_url) as r:\n",
    "                r.seek = lambda *args: None  # allow pydub to call seek(0)\n",
    "                pydub.AudioSegment.from_file(r).export(wav, \"wav\")\n",
    "\n",
    "            wav.seek(0)\n",
    "            y, sr = librosa.load(wav)\n",
    "\n",
    "            # mel-scaled power (energy-squared) spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(y,\n",
    "                                                      sr=sr,\n",
    "                                                      n_mels=128,\n",
    "                                                      hop_length=1024,\n",
    "                                                      n_fft=2048)\n",
    "            # Convert to log scale (dB). We'll use the peak power as reference.\n",
    "            log_mel_spec = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "            #make dimensions of the array smaller\n",
    "            log_mel_spec = np.resize(log_mel_spec, (128, 644))\n",
    "\n",
    "            log_mel_spec_arr = log_mel_spec.reshape(\n",
    "                log_mel_spec.shape[0], log_mel_spec.shape[1], 1)\n",
    "            pre_process = np.expand_dims(log_mel_spec_arr, axis=0)\n",
    "            pre_process = pre_process / 255\n",
    "            latent = model.predict(pre_process)\n",
    "            \n",
    "\n",
    "        except:\n",
    "            print('song has no useable url')\n",
    "            return\n",
    "    \n",
    "        #just going to keep it as a df for ease of use even though only 1 row\n",
    "        latent_df= pd.DataFrame(latent)\n",
    "        latent_df=latent_df.loc[~(latent_df==0).all(axis=1)]\n",
    "        latent_df['song_names']= name\n",
    "        latent_df['id']= song_id\n",
    "    \n",
    "    else:\n",
    "        print('song has no useable url')\n",
    "        return\n",
    "    \n",
    "    return (latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:32.193136Z",
     "start_time": "2020-04-08T14:25:32.049Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_music_quals(id_list):\n",
    "    '''get music qualities such as tempo and time sig\n",
    "        with a list of song ids'''\n",
    "    qualities={}\n",
    "    count=0\n",
    "    for song in id_list:\n",
    "        if type(song)==str:\n",
    "            quals=spotify.audio_features(song)\n",
    "            try:\n",
    "                qualities[song]=quals\n",
    "            except:\n",
    "                print(count)\n",
    "                count+=1\n",
    "    return qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:32.359422Z",
     "start_time": "2020-04-08T14:25:32.346874Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_spotify_quals(music_df):\n",
    "    '''get spotify music qualities and put into\n",
    "        dataframe then merge into main dataframe'''\n",
    "    #get ids of songs so can search spotify\n",
    "    id_list=list(music_df['id'].values)\n",
    "    #earlier function that helps look for music quals\n",
    "    quals = get_music_quals(id_list)\n",
    "    #put the qualities as column headers\n",
    "    df=pd.DataFrame(columns=list(quals[list(quals.keys())[0]][0].keys()))\n",
    "    for ind, key in enumerate(quals.keys()):\n",
    "    #iterate over songs and get the spotify qualities for each song into the df\n",
    "        song=quals[key]\n",
    "        try:\n",
    "            df.loc[ind]=list(song[0].values())\n",
    "        except:\n",
    "            print(song)\n",
    "    #merge the two dataframes together on id and return\n",
    "    orig_and_spotify =pd.merge(music_df,df,on='id',how='outer')\n",
    "    \n",
    "    #drop columns we dont really need\n",
    "    orig_and_spotify.drop(columns=['track_href','analysis_url','duration_ms','type','uri'],inplace=True)\n",
    "    #turning some of the columns into ints so can be used\n",
    "    #using try and except as there may be some NANs\n",
    "    try:\n",
    "        orig_and_spotify.key=orig_and_spotify.key.astype(int)\n",
    "        orig_and_spotify['mode']=orig_and_spotify['mode'].astype(int)\n",
    "        orig_and_spotify.time_signature=orig_and_spotify.time_signature.astype(int)\n",
    "        return orig_and_spotify\n",
    "    except:\n",
    "        return orig_and_spotify\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wanted to put the whole process into one function so can be used really easily and to be able to handle new songs really easily without the really long process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is for when a song is found within our mixes dataset - here we are going to use alternating least squares. The biggest reason I chose this form of matrix factorization over something like logistic matrix factorization is that I want to eventually re do this project in Spark for practice and Spark also has an alternating least squares library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:50.021453Z",
     "start_time": "2020-04-08T14:25:49.063654Z"
    }
   },
   "outputs": [],
   "source": [
    "collab_df=pd.read_csv('../song_collab_filtering/mixesdb_df_for_recs.csv')\n",
    "collab_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "plays= collab_df['size']\n",
    "users=collab_df.user_nums\n",
    "songs=collab_df.song_nums\n",
    "Matrix_us=coo_matrix((plays, (songs, users))).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:50.028206Z",
     "start_time": "2020-04-08T14:25:50.024258Z"
    }
   },
   "outputs": [],
   "source": [
    "#needed to make the training not take ages\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:50.041136Z",
     "start_time": "2020-04-08T14:25:50.032756Z"
    }
   },
   "outputs": [],
   "source": [
    "collab_model = AlternatingLeastSquares(factors=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:25:53.097090Z",
     "start_time": "2020-04-08T14:25:50.043214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26824dcd9b994fd494fcd15e20533649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collab_model.fit(Matrix_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:43:47.165970Z",
     "start_time": "2020-04-08T14:43:47.161052Z"
    }
   },
   "outputs": [],
   "source": [
    "a=collab_model.similar_items(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:44:01.772971Z",
     "start_time": "2020-04-08T14:44:01.769697Z"
    }
   },
   "outputs": [],
   "source": [
    "a=[val[0] for val in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T14:52:23.984868Z",
     "start_time": "2020-04-08T14:52:23.978878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['set_title', 'set_list', 'artist', 'song', 'spotify_song_name',\n",
       "       'spotify_id', 'preview', 'songs', 'set_title_split', 'user_nums',\n",
       "       'song_nums', 'size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collab_filter(song_id, user_song_df, num_songs=5):\n",
    "    '''\n",
    "    song_id = spotify id for individual song\n",
    "    user_song_df= dataframe with users, songs, playcounts etc\n",
    "    for the time being i am not going to enable filtering by key/tempo as not enough songs\n",
    "    but in future will do\n",
    "    '''\n",
    "\n",
    "    song_num = song_list[song_list.spotify_id == song_id].song_nums.values[0]\n",
    "    print(song_num)\n",
    "    print(type(song_num))\n",
    "    #orig_key = song_list[song_list.spotify_id==song_id].key.values[0]\n",
    "    #orig_tempo= song_list[song_list.spotify_id==song_id].tempo.values[0]\n",
    "\n",
    "    #check if you want songs of same key\n",
    "    #if same_key=='yes':\n",
    "    #if yes then filter out other keys\n",
    "    #    print(f'key:{orig_key}')\n",
    "    #    song_list = song_list[song_list.key ==orig_key]\n",
    "\n",
    "    #can also enter number to specify what key you want\n",
    "    # elif type(same_key) !=str:\n",
    "    #     song_list = song_list[song_list.key==same_key]\n",
    "\n",
    "    # check if you want similar tempo\n",
    "    #  if similar_tempo=='yes':\n",
    "    #     print(f'tempo:{orig_tempo}')\n",
    "    #if yes can also specify how similar you want it\n",
    "    #     lower= int(orig_tempo)-margin\n",
    "    #    higher=int(orig_tempo)+margin\n",
    "    #    song_list=song_list[song_list.tempo.between(lower,higher)]\n",
    "\n",
    "    #elif type(similar_tempo) !=str:\n",
    "    #can also specify a specific tempo that you want\n",
    "    #   song_list = song_list[song_list.tempo.between(int(similar_tempo)-margin,int(similar_tempo)+margin)]\n",
    "\n",
    "    # refined_ids=song_list.spotify_id\n",
    "\n",
    "    user_song_refined = user_song_df[user_song_df.spotify_id.isin(\n",
    "        refined_ids)].copy()\n",
    "\n",
    "    plays = user_song_refined['size']\n",
    "    user_nums = user_song_refined.user_nums\n",
    "    song_nums = user_song_refined.song_nums\n",
    "\n",
    "    B = coo_matrix((plays, (song_nums, user_nums))).tocsr()\n",
    "\n",
    "    model = AlternatingLeastSquares(factors=30)\n",
    "    model.fit(B)\n",
    "    songs_inds = model.similar_items(song_num, N=num_songs)\n",
    "    songs_inds = [tup[0] for tup in songs_inds]\n",
    "\n",
    "    return song_list[song_list.song_nums.isin(songs_inds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T19:41:31.868820Z",
     "start_time": "2020-02-21T19:41:28.909230Z"
    }
   },
   "outputs": [],
   "source": [
    "#load pretrained model\n",
    "model = load_model('more_data_08-2.07.h5')\n",
    "# take the last layer off the model so we can get to the latent features\n",
    "new_model =model\n",
    "new_model.layers.pop()\n",
    "new_model_2 = Model(new_model.input, new_model.layers[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T19:41:32.272953Z",
     "start_time": "2020-02-21T19:41:31.870999Z"
    }
   },
   "outputs": [],
   "source": [
    "music_df=pd.read_csv('music_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T12:44:48.115807Z",
     "start_time": "2020-02-19T12:44:48.102864Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T19:41:32.286542Z",
     "start_time": "2020-02-21T19:41:32.275202Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_similar_for_new(song_id,\n",
    "                        collab_df,\n",
    "                        music_df,\n",
    "                        model,\n",
    "                        num_songs=5,\n",
    "                        diff_genre='no',\n",
    "                        same_key='yes',\n",
    "                        similar_tempo='yes',\n",
    "                        margin=3,\n",
    "                        scaled=False):\n",
    "    '''\n",
    "        First checks if song in collaborative filtering database\n",
    "        if not it then checks if song id in music dataframe and \n",
    "        if song is in neither tries to create the spectrogram \n",
    "        and find spotify features for the specified song, \n",
    "        then finds similar songs to that song using the \n",
    "        aforementioned qualities\n",
    "    '''\n",
    "\n",
    "    if song_id in collab_df.spotify_id.unique():\n",
    "        return collab_filter\n",
    "    \n",
    "    #checks if song in music dataframe\n",
    "    if song_id in music_df.id.unique():\n",
    "        #if it is in the dataframe can just find similar songs\n",
    "        close_song_df = find_similar(song_id,\n",
    "                                     music_df,\n",
    "                                     num_songs=num_songs,\n",
    "                                     diff_genre=diff_genre,\n",
    "                                     same_key=same_key,\n",
    "                                     similar_tempo=similar_tempo,\n",
    "                                     margin=margin,\n",
    "                                     scaled=scaled)\n",
    "\n",
    "        return close_song_df\n",
    "\n",
    "    else:\n",
    "        track = spotify.track(song_id)\n",
    "        song_name = track['name']\n",
    "        preview_url = track['preview_url']\n",
    "        #check if the song has a url\n",
    "        if preview_url:\n",
    "            single_song_df = spectrogram_then_latent(preview_url, song_id,\n",
    "                                                     song_name, model)\n",
    "\n",
    "            #can just use the same spotify function as before\n",
    "            single_song_with_spotify = get_spotify_quals(single_song_df)\n",
    "\n",
    "            #sometimes the names of the columns can become strings/ints so need to check their the same\n",
    "            cols = [str(col) for col in list(single_song_with_spotify.columns)]\n",
    "\n",
    "            single_song_with_spotify.columns = cols\n",
    "            #need to remove genre approx in the future\n",
    "            single_song_with_spotify['genre_approx'] = 10\n",
    "            single_song_with_spotify = single_song_with_spotify.reindex(sorted(\n",
    "                single_song_with_spotify.columns),\n",
    "                                                                        axis=1)\n",
    "            music_df = pd.concat([music_df, single_song_with_spotify],\n",
    "                                 ignore_index=True)\n",
    "            #now we have song in dataframe can just do same process as the first bit of if statement\n",
    "            close_song_df = find_similar(song_id,\n",
    "                                         music_df,\n",
    "                                         num_songs=num_songs,\n",
    "                                         diff_genre=diff_genre,\n",
    "                                         same_key=same_key,\n",
    "                                         similar_tempo=similar_tempo,\n",
    "                                         margin=margin,\n",
    "                                         scaled=scaled)\n",
    "            return close_song_df\n",
    "\n",
    "        else:\n",
    "            print('song has no url/ no spotify info')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T20:57:19.488147Z",
     "start_time": "2020-02-21T20:57:17.266801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:6\n",
      "tempo:78.558\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_ids</th>\n",
       "      <th>song_names</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7KA4W4McWYRpgf0fWsJZWB</td>\n",
       "      <td>(See You Again (feat. Kali Uchis), Tyler, The ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7KA4W4McWYRpgf0fWsJZWB</td>\n",
       "      <td>(See You Again (feat. Kali Uchis), Tyler, The ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2RwS1tNuq1eKJvhxaZKp3x</td>\n",
       "      <td>(Olles leiwand, TTR Allstars)</td>\n",
       "      <td>7.220106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7ymbpIW2rzSKxRrtpWN80a</td>\n",
       "      <td>(Oh She, Samuel Gregory)</td>\n",
       "      <td>9.698834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0owUIdKletsUs6kMUlr32L</td>\n",
       "      <td>(reach out, Sweeps)</td>\n",
       "      <td>10.943082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2ysQz5RXNkX8ylV0WjbFDj</td>\n",
       "      <td>(Cypherspace, Da Staummtisch feat. Linz Rap Al...</td>\n",
       "      <td>11.383145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3iJAySzjUixQC1oWBzmPji</td>\n",
       "      <td>(october, oofoe)</td>\n",
       "      <td>11.454706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>68uaEf2jgIsUKwM9RrOiK6</td>\n",
       "      <td>(Good Thing, Jeangu Macrooy)</td>\n",
       "      <td>12.320747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4GxU9RLeOS2qqoj1Em53Ly</td>\n",
       "      <td>(2 Far, Dizzee Rascal)</td>\n",
       "      <td>12.550152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>38igNG6Dz0dJZU7AliitGJ</td>\n",
       "      <td>(Hugging You (Quietly), Jazzinuf)</td>\n",
       "      <td>12.649486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 song_ids                                         song_names  \\\n",
       "0  7KA4W4McWYRpgf0fWsJZWB  (See You Again (feat. Kali Uchis), Tyler, The ...   \n",
       "1  7KA4W4McWYRpgf0fWsJZWB  (See You Again (feat. Kali Uchis), Tyler, The ...   \n",
       "2  2RwS1tNuq1eKJvhxaZKp3x                      (Olles leiwand, TTR Allstars)   \n",
       "3  7ymbpIW2rzSKxRrtpWN80a                           (Oh She, Samuel Gregory)   \n",
       "4  0owUIdKletsUs6kMUlr32L                                (reach out, Sweeps)   \n",
       "5  2ysQz5RXNkX8ylV0WjbFDj  (Cypherspace, Da Staummtisch feat. Linz Rap Al...   \n",
       "6  3iJAySzjUixQC1oWBzmPji                                   (october, oofoe)   \n",
       "7  68uaEf2jgIsUKwM9RrOiK6                       (Good Thing, Jeangu Macrooy)   \n",
       "8  4GxU9RLeOS2qqoj1Em53Ly                             (2 Far, Dizzee Rascal)   \n",
       "9  38igNG6Dz0dJZU7AliitGJ                  (Hugging You (Quietly), Jazzinuf)   \n",
       "\n",
       "   distances  \n",
       "0   0.000000  \n",
       "1   0.000000  \n",
       "2   7.220106  \n",
       "3   9.698834  \n",
       "4  10.943082  \n",
       "5  11.383145  \n",
       "6  11.454706  \n",
       "7  12.320747  \n",
       "8  12.550152  \n",
       "9  12.649486  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_for_new('7KA4W4McWYRpgf0fWsJZWB',music_df,new_model_2,same_key='yes',num_songs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T20:46:57.170591Z",
     "start_time": "2020-02-21T20:46:57.091010Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-30410dee6d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1BA4OdphRNKQSeHrMHLAWg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmusic_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiff_genre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'no'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msame_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'yes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_songs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-ac31dc77e0ad>\u001b[0m in \u001b[0;36mfind_similar\u001b[0;34m(song_id, song_list, num_songs, diff_genre, same_key, similar_tempo, margin, scaled)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msong_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msong_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0msong_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4279\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4280\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "find_similar('1BA4OdphRNKQSeHrMHLAWg',music_df,diff_genre='no',same_key='yes',num_songs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'4KjNEsQ4jkqXwCmsn71a9p'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
