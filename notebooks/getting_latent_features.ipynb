{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T09:58:30.316459Z",
     "start_time": "2020-03-03T09:58:16.692577Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import config\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D,AveragePooling2D, BatchNormalization,Dropout,Flatten,Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.util as util\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, pairwise_distances\n",
    "plt.style.use('ggplot')\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import io\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import glob\n",
    "\n",
    "\n",
    "import pydub\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from shutil import copyfileobj\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen, Request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T09:55:07.440728Z",
     "start_time": "2020-03-03T09:55:02.773Z"
    }
   },
   "outputs": [],
   "source": [
    "#load pretrained model\n",
    "model = load_model('more_data_08-2.07.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T09:54:49.383042Z",
     "start_time": "2020-03-03T09:54:49.368360Z"
    }
   },
   "outputs": [],
   "source": [
    "# take the last layer off the model so we can get to the latent features\n",
    "new_model =model\n",
    "new_model.layers.pop()\n",
    "new_model_2 = Model(new_model.input, new_model.layers[-3].output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T12:55:44.006586Z",
     "start_time": "2020-02-06T12:55:43.993435Z"
    }
   },
   "source": [
    "After going through a number of different processes I realised the most memory efficent way of doing this process is creating the spectrogram and then immediately running it through the CNN without saving it down and then just store the latent features of each song. This avoids having to save loads of spectrograms that take up a load of memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spotify_quals(music_df):\n",
    "    '''get spotify music qualities and put into\n",
    "        dataframe then merge into main dataframe'''\n",
    "    #get ids of songs so can search spotify\n",
    "    id_list=list(music_df['id'].values)\n",
    "    #earlier function that helps look for music quals\n",
    "    quals = get_music_quals(id_list)\n",
    "    #put the qualities as column headers\n",
    "    df=pd.DataFrame(columns=list(quals[list(quals.keys())[0]][0].keys()))\n",
    "    for ind, key in enumerate(quals.keys()):\n",
    "    #iterate over songs and get the spotify qualities for each song into the df\n",
    "        song=quals[key]\n",
    "        try:\n",
    "            df.loc[ind]=list(song[0].values())\n",
    "        except:\n",
    "            print(song)\n",
    "    #merge the two dataframes together on id and return\n",
    "    orig_and_spotify =pd.merge(music_df,df,on='id',how='outer')\n",
    "    \n",
    "    #drop columns we dont really need\n",
    "    orig_and_spotify.drop(columns=['track_href','analysis_url','duration_ms','type','uri'],inplace=True)\n",
    "    #turning some of the columns into ints so can be used\n",
    "    #using try and except as there may be some NANs\n",
    "    try:\n",
    "        orig_and_spotify.key=orig_and_spotify.key.astype(int)\n",
    "        orig_and_spotify['mode']=orig_and_spotify['mode'].astype(int)\n",
    "        orig_and_spotify.time_signature=orig_and_spotify.time_signature.astype(int)\n",
    "        return orig_and_spotify\n",
    "    except:\n",
    "        return orig_and_spotify\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T11:52:05.982020Z",
     "start_time": "2020-02-18T11:52:05.967878Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_songs_from_playlist_search(playlist=None,limit=10,artist_name='techno'):\n",
    "    '''takes a search term such as techno, finds playlists with techno\n",
    "        in the name and then returns information about the songs in\n",
    "        the playlist. Can also take individual playlist.'''\n",
    "    playlist_ids=[]\n",
    "    song_ids = []\n",
    "    playlists =[]\n",
    "    song_ids=[]\n",
    "    preview_urls=[]\n",
    "    song_names=[]\n",
    "    \n",
    "    count=0\n",
    "    if playlist !=None:\n",
    "        playlist_ids.append(playlist)\n",
    "    else:\n",
    "        results = spotify.search(q=artist_name,limit=limit, type='playlist')\n",
    "    #find playlists with specific search term\n",
    "        for playlist_info in results['playlists']['items']:\n",
    "            playlist_ids.append(playlist_info['id'])\n",
    "    \n",
    "    #add all the songs in the playlists to another list\n",
    "    for playlist in playlist_ids:\n",
    "        source_playlist=spotify.user_playlist(username,playlist)\n",
    "        song_set=source_playlist['tracks']\n",
    "        songs=song_set['items']\n",
    "        \n",
    "        while song_set['next']:\n",
    "            song_set=spotify.next(song_set)\n",
    "            for song in song_set['items']:\n",
    "                songs.append(song)\n",
    "        playlists.append(songs)\n",
    "    \n",
    "        \n",
    "   \n",
    "    #loop over the song lists and extract information\n",
    "    for song_list in playlists:\n",
    "        for track in song_list:\n",
    "            \n",
    "            try:\n",
    "                if track['track']['id']==None:\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        song_ids.append(track['track']['id'])\n",
    "                        song_names.append(track['track']['name'])\n",
    "                        preview_urls.append(track['track']['preview_url'])\n",
    "\n",
    "                    except:\n",
    "                        print(count)\n",
    "                        count+=1\n",
    "            except:\n",
    "                print(count)\n",
    "                count+=1\n",
    "    \n",
    "    return (song_ids,song_names,preview_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T11:37:25.823930Z",
     "start_time": "2020-02-19T11:37:25.656491Z"
    }
   },
   "outputs": [],
   "source": [
    "#keep having to rerun this as spotify API sometimes needs reloading\n",
    "client_id= config.client_id\n",
    "client_secret =config.client_secret\n",
    "\n",
    "username = '1143043561'\n",
    "auth = SpotifyClientCredentials(\n",
    "client_id=client_id,\n",
    "client_secret=client_secret\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    token = auth.get_access_token()\n",
    "except:\n",
    "    os.remove(f'.cache-{username}')\n",
    "    token = auth.get_access_token()\n",
    "\n",
    "#create spotify object\n",
    "spotify = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T11:52:06.102532Z",
     "start_time": "2020-02-18T11:52:06.086784Z"
    }
   },
   "outputs": [],
   "source": [
    "def spectrograms_then_latent(url_list, id_list, names_list, model):\n",
    "    '''takes list of urls and turns the preview mp3 \n",
    "        into a spectrogram and then uses a model to \n",
    "        extract latent features'''\n",
    "    \n",
    "    print(len(url_list))\n",
    "    print(len(id_list))\n",
    "    latent_array = np.zeros((len(url_list), 40))\n",
    "    fin_ids=[]\n",
    "    fin_names=[]\n",
    "\n",
    "    count = 0\n",
    "    for ind, url in enumerate(url_list):\n",
    "\n",
    "        if url != None:\n",
    "            try:\n",
    "                mp3_url = url\n",
    "                wav = io.BytesIO()\n",
    "                with urlopen(mp3_url) as r:\n",
    "                    r.seek = lambda *args: None  # allow pydub to call seek(0)\n",
    "                    pydub.AudioSegment.from_file(r).export(wav, \"wav\")\n",
    "\n",
    "                wav.seek(0)\n",
    "                y, sr = librosa.load(wav)\n",
    "\n",
    "                # mel-scaled power (energy-squared) spectrogram\n",
    "                mel_spec = librosa.feature.melspectrogram(y,\n",
    "                                                          sr=sr,\n",
    "                                                          n_mels=128,\n",
    "                                                          hop_length=1024,\n",
    "                                                          n_fft=2048)\n",
    "                # Convert to log scale (dB). We'll use the peak power as reference.\n",
    "                log_mel_spec = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "                #make dimensions of the array smaller\n",
    "                log_mel_spec = np.resize(log_mel_spec, (128, 644))\n",
    "\n",
    "                log_mel_spec_arr = log_mel_spec.reshape(\n",
    "                    log_mel_spec.shape[0], log_mel_spec.shape[1], 1)\n",
    "                pre_process = np.expand_dims(log_mel_spec_arr, axis=0)\n",
    "                pre_process = pre_process / 255\n",
    "                latent = model.predict(pre_process)\n",
    "                latent_array[ind, :] = latent\n",
    "                fin_ids.append(id_list[ind])\n",
    "                fin_names.append(names_list[ind])\n",
    "                \n",
    "            except:\n",
    "                count += 1\n",
    "                \n",
    "                fin_ids.append(None)\n",
    "                fin_names.append(None)\n",
    "    \n",
    "    print(f'missing{count} songs')\n",
    "    latent_df= pd.DataFrame(latent_array)\n",
    "    #because the latent array was init with loads of 0s need to remove the rows with only 0s\n",
    "    #as they will be the ones that the model could not process\n",
    "    latent_df=latent_df.loc[~(latent_df==0).all(axis=1)]\n",
    "    latent_df['song_names']= fin_names\n",
    "    latent_df['id']= fin_ids\n",
    "    \n",
    "    return (latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T17:40:24.568567Z",
     "start_time": "2020-03-22T17:40:24.214679Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df =pd.DataFrame()\n",
    "search_terms =['soul','disco','nts radio','text records','nina kraviz','kaytranada','instrumental hip hop']\n",
    "for ind,  term in enumerate(search_terms):\n",
    "    #loop was taking too long so would time out\n",
    "    client_id= config.client_id\n",
    "    client_secret =config.client_secret\n",
    "\n",
    "    username = '1143043561'\n",
    "    auth = SpotifyClientCredentials(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret\n",
    "    )\n",
    "\n",
    "\n",
    "    try:\n",
    "        token = auth.get_access_token()\n",
    "    except:\n",
    "        os.remove(f'.cache-{username}')\n",
    "        token = auth.get_access_token()\n",
    "\n",
    "    #create spotify object\n",
    "    spotify = spotipy.Spotify(auth=token)\n",
    "    ids, names, urls =get_songs_from_playlist_search(artist_name=term)\n",
    "    latent_df=spectrograms_then_latent(urls, ids, names, new_model_2)\n",
    "    new_df=new_df.append(latent_df,ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_music_quals(id_list):\n",
    "    '''get music qualities such as tempo and time sig\n",
    "        with a list of song ids'''\n",
    "    qualities={}\n",
    "    count=0\n",
    "    for song in id_list:\n",
    "        if type(song)==str:\n",
    "            quals=spotify.audio_features(song)\n",
    "            try:\n",
    "                qualities[song]=quals\n",
    "            except:\n",
    "                print(count)\n",
    "                count+=1\n",
    "    return qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spotify_quals(music_df):\n",
    "    '''get spotify music qualities and put into\n",
    "        dataframe then merge into main dataframe'''\n",
    "    #get ids of songs so can search spotify\n",
    "    id_list=list(music_df['id'].values)\n",
    "    #earlier function that helps look for music quals\n",
    "    quals = get_music_quals(id_list)\n",
    "    #put the qualities as column headers\n",
    "    df=pd.DataFrame(columns=list(quals[list(quals.keys())[0]][0].keys()))\n",
    "    for ind, key in enumerate(quals.keys()):\n",
    "    #iterate over songs and get the spotify qualities for each song into the df\n",
    "        song=quals[key]\n",
    "        try:\n",
    "            df.loc[ind]=list(song[0].values())\n",
    "        except:\n",
    "            print(song)\n",
    "    #merge the two dataframes together on id and return\n",
    "    orig_and_spotify =pd.merge(music_df,df,on='id',how='outer')\n",
    "    \n",
    "    #drop columns we dont really need\n",
    "    orig_and_spotify.drop(columns=['track_href','analysis_url','duration_ms','type','uri'],inplace=True)\n",
    "    #turning some of the columns into ints so can be used\n",
    "    #using try and except as there may be some NANs\n",
    "    try:\n",
    "        orig_and_spotify.key=orig_and_spotify.key.astype(int)\n",
    "        orig_and_spotify['mode']=orig_and_spotify['mode'].astype(int)\n",
    "        orig_and_spotify.time_signature=orig_and_spotify.time_signature.astype(int)\n",
    "        return orig_and_spotify\n",
    "    except:\n",
    "        return orig_and_spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T11:58:42.371438Z",
     "start_time": "2020-02-19T11:37:28.590529Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df_with_spotify=get_spotify_quals(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T12:06:21.964106Z",
     "start_time": "2020-02-19T12:06:21.938541Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df_with_spotify.dropna(inplace=True)\n",
    "#had to do the below seperately because i wanted to check what had na values\n",
    "new_df_with_spotify.key=new_df_with_spotify.key.astype(int)\n",
    "new_df_with_spotify['mode']=new_df_with_spotify['mode'].astype(int)\n",
    "new_df_with_spotify.time_signature=new_df_with_spotify.time_signature.astype(int)\n",
    "new_df_with_spotify.columns=cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T12:08:10.614065Z",
     "start_time": "2020-02-19T12:08:10.536904Z"
    }
   },
   "outputs": [],
   "source": [
    "#putting into main dataframe\n",
    "music_values=pd.concat([music_values,new_df_with_spotify], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T12:09:11.923704Z",
     "start_time": "2020-02-19T12:09:09.825066Z"
    }
   },
   "outputs": [],
   "source": [
    "#dropping duplicates and saving to csv\n",
    "music_values.drop_duplicates(subset='id',inplace=True)\n",
    "music_values.to_csv('music_values.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
